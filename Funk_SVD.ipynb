{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook ideas of Simon Funk's SVD approach are used to fit two feature matrices on a given utility matrix. The feature matrices correspond to latent movie features and latent user features. Based on the matrix multiplication of the feature matrices the utility matrix is approximated. The fitted feature matrices are then used to make predictions for a separate test set. \n",
    "\n",
    "- The movie & rating data is based on the MovieLens 100K (09/2018) data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:41:59.925787Z",
     "start_time": "2020-06-29T14:41:59.617145Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.ma as ma \n",
    "from utility_matrix_prep import create_utility_matrix, get_merged_ratings_df\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:00.139237Z",
     "start_time": "2020-06-29T14:42:00.091813Z"
    }
   },
   "outputs": [],
   "source": [
    "#load ratings data:\n",
    "path = '/media/vincent/harddrive/Movielens_data/ml-small_09_2018/'\n",
    "file_name = 'ratings.csv'\n",
    "\n",
    "rating_data = pd.read_csv(path + file_name,  encoding = \"ISO-8859-1\", header=0)\n",
    "\n",
    "#load movies data:\n",
    "movies_data = pd.read_csv(path + 'movies.csv',encoding = \"ISO-8859-1\", header=0)\n",
    "#adjust some col-labels:\n",
    "movies_data['movie_title'] = movies_data['title']\n",
    "movies_data = movies_data[['movieId','movie_title','genres']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is sorted by the given timestamps. The most recent ratings of each user are used as test set (most recent 20%). The remaining ratings make up the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:00.997913Z",
     "start_time": "2020-06-29T14:42:00.987763Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(data_df, ratio = 0.2):\n",
    "    \n",
    "    '''\n",
    "    creates test_set based on most recent x% of ratings for each user \n",
    "    remaining entries are used as training set\n",
    "    '''\n",
    "    \n",
    "    test_set = pd.DataFrame(columns=data_df.columns)\n",
    "    train_set = pd.DataFrame(columns=data_df.columns)\n",
    "\n",
    "    grouped_ratings = data_df.groupby('userId')\n",
    "    \n",
    "    #get most recent ratings of each user and split into train & testset:\n",
    "    for name, group in grouped_ratings:\n",
    "        set_size = int(group.shape[0] * ratio)\n",
    "        temp_test = group.sort_values('timestamp').iloc[group.shape[0]-1-set_size:] #slice last (most recent) rows of sorted df\n",
    "        temp_train = group.sort_values('timestamp').iloc[:group.shape[0]-2-set_size] #slice first rows of sorted df\n",
    "        \n",
    "        test_set = pd.concat([test_set, temp_test])\n",
    "        train_set = pd.concat([train_set, temp_train])\n",
    "        \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:07.797924Z",
     "start_time": "2020-06-29T14:42:01.211523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_ratings:  (79676, 4)\n",
      "shape of test_ratings:  (20550, 4)\n",
      "\n",
      " test set before processing: \n",
      "  \n",
      "     userId movieId  rating  timestamp\n",
      "192      1    2959     5.0  964983282\n",
      "176      1    2654     5.0  964983393\n",
      "\n",
      " test set after processing: \n",
      "  \n",
      "    userId           movie_title  rating\n",
      "0  User_1     Fight Club (1999)     5.0\n",
      "1  User_1  Wolf Man, The (1941)     5.0\n"
     ]
    }
   ],
   "source": [
    "#split data:\n",
    "train_ratings, test_ratings = train_test_split(rating_data, ratio = 0.2)\n",
    "print('shape of train_ratings: ', train_ratings.shape)\n",
    "print('shape of test_ratings: ', test_ratings.shape)\n",
    "\n",
    "# prepare test_set:\n",
    "print('\\n test set before processing: \\n  \\n', test_ratings.head(2))\n",
    "#call custom function:\n",
    "test_ratings = get_merged_ratings_df(test_ratings,movies_data)\n",
    "test_ratings['userId'] = test_ratings['userId'].apply(lambda row: 'User_' + str(row))\n",
    "print('\\n test set after processing: \\n  \\n', test_ratings.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Utility Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training set, the utility matrix is created which contains the ratings for each user as a row entry. Columns indicate the different movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:08.754816Z",
     "start_time": "2020-06-29T14:42:07.847422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of duplicated entries:  0\n",
      "shape of utility matrix:  (610, 9737)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <th>Jumanji (1995)</th>\n",
       "      <th>Grumpier Old Men (1995)</th>\n",
       "      <th>Waiting to Exhale (1995)</th>\n",
       "      <th>Father of the Bride Part II (1995)</th>\n",
       "      <th>Heat (1995)</th>\n",
       "      <th>Sabrina (1995)</th>\n",
       "      <th>Tom and Huck (1995)</th>\n",
       "      <th>Sudden Death (1995)</th>\n",
       "      <th>GoldenEye (1995)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Toy Story (1995)  Jumanji (1995)  Grumpier Old Men (1995)  \\\n",
       "User_1               4.0             NaN                      4.0   \n",
       "User_2               NaN             NaN                      NaN   \n",
       "User_3               NaN             NaN                      NaN   \n",
       "User_4               NaN             NaN                      NaN   \n",
       "User_5               4.0             NaN                      NaN   \n",
       "\n",
       "        Waiting to Exhale (1995)  Father of the Bride Part II (1995)  \\\n",
       "User_1                       NaN                                 NaN   \n",
       "User_2                       NaN                                 NaN   \n",
       "User_3                       NaN                                 NaN   \n",
       "User_4                       NaN                                 NaN   \n",
       "User_5                       NaN                                 NaN   \n",
       "\n",
       "        Heat (1995)  Sabrina (1995)  Tom and Huck (1995)  Sudden Death (1995)  \\\n",
       "User_1          4.0             NaN                  NaN                  NaN   \n",
       "User_2          NaN             NaN                  NaN                  NaN   \n",
       "User_3          NaN             NaN                  NaN                  NaN   \n",
       "User_4          NaN             NaN                  NaN                  NaN   \n",
       "User_5          NaN             NaN                  NaN                  NaN   \n",
       "\n",
       "        GoldenEye (1995)  \n",
       "User_1               NaN  \n",
       "User_2               NaN  \n",
       "User_3               NaN  \n",
       "User_4               NaN  \n",
       "User_5               NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call custom function to create utility matrix\n",
    "train_utilmatrix = create_utility_matrix(ratings_df = train_ratings, movies_df = movies_data)\n",
    "print('shape of utility matrix: ', train_utilmatrix.shape)\n",
    "\n",
    "#get glimpse on utility matrix:\n",
    "train_utilmatrix.iloc[0:5,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function & Update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the approach of Simon Funk, a function is defined to fit two feature matrices (\"latent_users\" & \"latent_movies\") which are learned to predict the actual user ratings through matrix multiplication. Batch Gradient Descent is used to train the feature matrices. Since the idea is inspired by the SVD technique, it is known as \"Funk SVD\".\n",
    "\n",
    "**Parameters to define**:\n",
    "\n",
    "- alpha learning rate\n",
    "- regularization term\n",
    "- number of training iterations\n",
    "- dimensions of feature matrices\n",
    "\n",
    "**addtional parameters**:\n",
    "\n",
    "- normalize utility matrix by subtracting average movie ratings\n",
    "- \"baseline\" flag adds the mean movie rating and the average user's offset\n",
    "*(the offset is defined as \"average offset between a user's rating and the movie's average rating, for every user\")*\n",
    "\n",
    "\n",
    "**Note**: So far, I couldn't find a combination of the additional parameters that beats the result of a \"simple\" Batch Gradient Descent training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:09.322939Z",
     "start_time": "2020-06-29T14:42:09.311916Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_GD_fsvd(util_matrix = None, latent_users = None, latent_movies = None, \n",
    "                                alpha = 0.00001, regul = 0.00001, n_iter=100, \n",
    "                                mean_normalize = False, baseline = False, verbose=0):\n",
    "    \n",
    "    \n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(util_matrix)\n",
    "    #create masked array:\n",
    "    util_masked = np.ma.masked_array(util_matrix, mask)\n",
    "    \n",
    "    #calculate mean without considering the NaN values:\n",
    "    movie_means = np.mean(util_masked, axis=0)\n",
    "    \n",
    "    #as suggested by Simon Funk calcualte user offset:\n",
    "    offset = util_masked - movie_means\n",
    "    avg_offset = np.mean(offset, axis=1)\n",
    "    avg_offset = np.reshape(avg_offset, (-1,1))\n",
    "    \n",
    "               \n",
    "    #fill NaN values with \"0\" --> through matrix multiplication \"0\" values do not contribute to loss & gradient\n",
    "    util_masked = util_masked.filled(0)\n",
    "    \n",
    "    if mean_normalize == True:\n",
    "\n",
    "        #apply mean normalization:\n",
    "        util_masked = util_masked - movie_means\n",
    "    \n",
    "    \n",
    "    #create list to store loss information\n",
    "    loss_list = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        if baseline == True and mean_normalize == False:\n",
    "            preds = np.dot(latent_users, latent_movies) + movie_means + avg_offset\n",
    "\n",
    "        else:\n",
    "            preds = np.dot(latent_users, latent_movies) \n",
    "          \n",
    "        #apply mask again to only consider predictions for which we have actual values given in training set\n",
    "        preds_mask = np.ma.array(preds, mask=mask)\n",
    "        #fill NaNs with 0 --> through matrix multiplication \"0\" values do not contribute to loss & gradient\n",
    "        preds = preds_mask.filled(0)\n",
    "        \n",
    "        #calculate error:\n",
    "        error_matrix = preds - util_masked\n",
    "                \n",
    "        loss = (1/2) * np.sum(error_matrix**2) + (regul/2) * np.sum(latent_users**2) + (regul/2) * np.sum(latent_movies**2)\n",
    "        mse_error = np.sum(error_matrix**2)/util_masked.shape[0]\n",
    "        \n",
    "        #store result:\n",
    "        loss_list.append([loss,mse_error,i])\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Iteration ', i)\n",
    "            print('Current loss: ', loss , ' \\n')\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print('Latent User features sample: \\n', latent_users[0:5,:5])\n",
    "        \n",
    "        #update latent_user features:\n",
    "        latent_users = latent_users - alpha*(np.dot(error_matrix,latent_movies.transpose()) + regul*latent_users)\n",
    "        \n",
    "        #update latent movie features:\n",
    "        latent_movies = latent_movies - alpha*(np.dot(latent_users.transpose(),error_matrix) + regul*latent_movies)\n",
    "        \n",
    "        \n",
    "    #return non-masked matrices & training information:  \n",
    "    return np.ma.getdata(latent_users), np.ma.getdata(latent_movies), np.ma.getdata(movie_means), np.ma.getdata(avg_offset), np.array(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of the feature matrices are defined and the matrices are initialized randomly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:29.027954Z",
     "start_time": "2020-06-29T14:42:10.681774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Current loss:  154064.69070145383  \n",
      "\n",
      "Iteration  1\n",
      "Current loss:  147765.15378887896  \n",
      "\n",
      "Iteration  2\n",
      "Current loss:  142192.8002392737  \n",
      "\n",
      "Iteration  3\n",
      "Current loss:  137231.48798988317  \n",
      "\n",
      "Iteration  4\n",
      "Current loss:  132786.40132785361  \n",
      "\n",
      "Iteration  5\n",
      "Current loss:  128779.88118870601  \n",
      "\n",
      "Iteration  6\n",
      "Current loss:  125148.09829086057  \n",
      "\n",
      "Iteration  7\n",
      "Current loss:  121838.39480176593  \n",
      "\n",
      "Iteration  8\n",
      "Current loss:  118807.15703216897  \n",
      "\n",
      "Iteration  9\n",
      "Current loss:  116018.11050560385  \n",
      "\n",
      "Iteration  10\n",
      "Current loss:  113440.95141768902  \n",
      "\n",
      "Iteration  11\n",
      "Current loss:  111050.24634391088  \n",
      "\n",
      "Iteration  12\n",
      "Current loss:  108824.54612586435  \n",
      "\n",
      "Iteration  13\n",
      "Current loss:  106745.6709792734  \n",
      "\n",
      "Iteration  14\n",
      "Current loss:  104798.13265666379  \n",
      "\n",
      "Iteration  15\n",
      "Current loss:  102968.66645815058  \n",
      "\n",
      "Iteration  16\n",
      "Current loss:  101245.85140261687  \n",
      "\n",
      "Iteration  17\n",
      "Current loss:  99619.80125211364  \n",
      "\n",
      "Iteration  18\n",
      "Current loss:  98081.9125631001  \n",
      "\n",
      "Iteration  19\n",
      "Current loss:  96624.65870676373  \n",
      "\n",
      "Iteration  20\n",
      "Current loss:  95241.42100503406  \n",
      "\n",
      "Iteration  21\n",
      "Current loss:  93926.34988569452  \n",
      "\n",
      "Iteration  22\n",
      "Current loss:  92674.25036145367  \n",
      "\n",
      "Iteration  23\n",
      "Current loss:  91480.48725687558  \n",
      "\n",
      "Iteration  24\n",
      "Current loss:  90340.90650148802  \n",
      "\n",
      "Iteration  25\n",
      "Current loss:  89251.76952295385  \n",
      "\n",
      "Iteration  26\n",
      "Current loss:  88209.69834726173  \n",
      "\n",
      "Iteration  27\n",
      "Current loss:  87211.62947228909  \n",
      "\n",
      "Iteration  28\n",
      "Current loss:  86254.77494979794  \n",
      "\n",
      "Iteration  29\n",
      "Current loss:  85336.589407127  \n",
      "\n",
      "Iteration  30\n",
      "Current loss:  84454.74197810718  \n",
      "\n",
      "Iteration  31\n",
      "Current loss:  83607.092304617  \n",
      "\n",
      "Iteration  32\n",
      "Current loss:  82791.66992491431  \n",
      "\n",
      "Iteration  33\n",
      "Current loss:  82006.65648982904  \n",
      "\n",
      "Iteration  34\n",
      "Current loss:  81250.37034892611  \n",
      "\n",
      "Iteration  35\n",
      "Current loss:  80521.25313058014  \n",
      "\n",
      "Iteration  36\n",
      "Current loss:  79817.85800626595  \n",
      "\n",
      "Iteration  37\n",
      "Current loss:  79138.83938331825  \n",
      "\n",
      "Iteration  38\n",
      "Current loss:  78482.9438143146  \n",
      "\n",
      "Iteration  39\n",
      "Current loss:  77849.00194705807  \n",
      "\n",
      "Iteration  40\n",
      "Current loss:  77235.9213684132  \n",
      "\n",
      "Iteration  41\n",
      "Current loss:  76642.68021923178  \n",
      "\n",
      "Iteration  42\n",
      "Current loss:  76068.32147730725  \n",
      "\n",
      "Iteration  43\n",
      "Current loss:  75511.9478215038  \n",
      "\n",
      "Iteration  44\n",
      "Current loss:  74972.71700359687  \n",
      "\n",
      "Iteration  45\n",
      "Current loss:  74449.83766543715  \n",
      "\n",
      "Iteration  46\n",
      "Current loss:  73942.5655482465  \n",
      "\n",
      "Iteration  47\n",
      "Current loss:  73450.2000485161  \n",
      "\n",
      "Iteration  48\n",
      "Current loss:  72972.08108137299  \n",
      "\n",
      "Iteration  49\n",
      "Current loss:  72507.58621764522  \n",
      "\n",
      "Iteration  50\n",
      "Current loss:  72056.1280653682  \n",
      "\n",
      "Iteration  51\n",
      "Current loss:  71617.15187028231  \n",
      "\n",
      "Iteration  52\n",
      "Current loss:  71190.1333130993  \n",
      "\n",
      "Iteration  53\n",
      "Current loss:  70774.57648405702  \n",
      "\n",
      "Iteration  54\n",
      "Current loss:  70370.01201762947  \n",
      "\n",
      "Iteration  55\n",
      "Current loss:  69975.99537225835  \n",
      "\n",
      "Iteration  56\n",
      "Current loss:  69592.10524170962  \n",
      "\n",
      "Iteration  57\n",
      "Current loss:  69217.94208613799  \n",
      "\n",
      "Iteration  58\n",
      "Current loss:  68853.12677224596  \n",
      "\n",
      "Iteration  59\n",
      "Current loss:  68497.29931303841  \n",
      "\n",
      "Iteration  60\n",
      "Current loss:  68150.11769866344  \n",
      "\n",
      "Iteration  61\n",
      "Current loss:  67811.25681068329  \n",
      "\n",
      "Iteration  62\n",
      "Current loss:  67480.40741288441  \n",
      "\n",
      "Iteration  63\n",
      "Current loss:  67157.27521239256  \n",
      "\n",
      "Iteration  64\n",
      "Current loss:  66841.57998545848  \n",
      "\n",
      "Iteration  65\n",
      "Current loss:  66533.05476279944  \n",
      "\n",
      "Iteration  66\n",
      "Current loss:  66231.44506985068  \n",
      "\n",
      "Iteration  67\n",
      "Current loss:  65936.50821769443  \n",
      "\n",
      "Iteration  68\n",
      "Current loss:  65648.01264081376  \n",
      "\n",
      "Iteration  69\n",
      "Current loss:  65365.73727814527  \n",
      "\n",
      "Iteration  70\n",
      "Current loss:  65089.47099421299  \n",
      "\n",
      "Iteration  71\n",
      "Current loss:  64819.012037392444  \n",
      "\n",
      "Iteration  72\n",
      "Current loss:  64554.167532601925  \n",
      "\n",
      "Iteration  73\n",
      "Current loss:  64294.7530059374  \n",
      "\n",
      "Iteration  74\n",
      "Current loss:  64040.59193897319  \n",
      "\n",
      "Iteration  75\n",
      "Current loss:  63791.51535062651  \n",
      "\n",
      "Iteration  76\n",
      "Current loss:  63547.36140465618  \n",
      "\n",
      "Iteration  77\n",
      "Current loss:  63307.97504101537  \n",
      "\n",
      "Iteration  78\n",
      "Current loss:  63073.207629414035  \n",
      "\n",
      "Iteration  79\n",
      "Current loss:  62842.916643576245  \n",
      "\n",
      "Iteration  80\n",
      "Current loss:  62616.96535479086  \n",
      "\n",
      "Iteration  81\n",
      "Current loss:  62395.22254346003  \n",
      "\n",
      "Iteration  82\n",
      "Current loss:  62177.56222744708  \n",
      "\n",
      "Iteration  83\n",
      "Current loss:  61963.86340611341  \n",
      "\n",
      "Iteration  84\n",
      "Current loss:  61754.00981901693  \n",
      "\n",
      "Iteration  85\n",
      "Current loss:  61547.88971831747  \n",
      "\n",
      "Iteration  86\n",
      "Current loss:  61345.39565400513  \n",
      "\n",
      "Iteration  87\n",
      "Current loss:  61146.424271130134  \n",
      "\n",
      "Iteration  88\n",
      "Current loss:  60950.8761182715  \n",
      "\n",
      "Iteration  89\n",
      "Current loss:  60758.65546653627  \n",
      "\n",
      "Iteration  90\n",
      "Current loss:  60569.670138427755  \n",
      "\n",
      "Iteration  91\n",
      "Current loss:  60383.83134597373  \n",
      "\n",
      "Iteration  92\n",
      "Current loss:  60201.053537537955  \n",
      "\n",
      "Iteration  93\n",
      "Current loss:  60021.25425278935  \n",
      "\n",
      "Iteration  94\n",
      "Current loss:  59844.353985327856  \n",
      "\n",
      "Iteration  95\n",
      "Current loss:  59670.27605250872  \n",
      "\n",
      "Iteration  96\n",
      "Current loss:  59498.946472031916  \n",
      "\n",
      "Iteration  97\n",
      "Current loss:  59330.29384489645  \n",
      "\n",
      "Iteration  98\n",
      "Current loss:  59164.24924434204  \n",
      "\n",
      "Iteration  99\n",
      "Current loss:  59000.74611042875  \n",
      "\n",
      "Iteration  100\n",
      "Current loss:  58839.72014992579  \n",
      "\n",
      "Iteration  101\n",
      "Current loss:  58681.1092412044  \n",
      "\n",
      "Iteration  102\n",
      "Current loss:  58524.85334384525  \n",
      "\n",
      "Iteration  103\n",
      "Current loss:  58370.894412695954  \n",
      "\n",
      "Iteration  104\n",
      "Current loss:  58219.1763161231  \n",
      "\n",
      "Iteration  105\n",
      "Current loss:  58069.64475822611  \n",
      "\n",
      "Iteration  106\n",
      "Current loss:  57922.24720479287  \n",
      "\n",
      "Iteration  107\n",
      "Current loss:  57776.93281278751  \n",
      "\n",
      "Iteration  108\n",
      "Current loss:  57633.652363178444  \n",
      "\n",
      "Iteration  109\n",
      "Current loss:  57492.35819692482  \n",
      "\n",
      "Iteration  110\n",
      "Current loss:  57353.004153948605  \n",
      "\n",
      "Iteration  111\n",
      "Current loss:  57215.5455149345  \n",
      "\n",
      "Iteration  112\n",
      "Current loss:  57079.938945804264  \n",
      "\n",
      "Iteration  113\n",
      "Current loss:  56946.142444725076  \n",
      "\n",
      "Iteration  114\n",
      "Current loss:  56814.115291519185  \n",
      "\n",
      "Iteration  115\n",
      "Current loss:  56683.81799934763  \n",
      "\n",
      "Iteration  116\n",
      "Current loss:  56555.21226855191  \n",
      "\n",
      "Iteration  117\n",
      "Current loss:  56428.260942541914  \n",
      "\n",
      "Iteration  118\n",
      "Current loss:  56302.92796562434  \n",
      "\n",
      "Iteration  119\n",
      "Current loss:  56179.17834267463  \n",
      "\n",
      "Iteration  120\n",
      "Current loss:  56056.97810055881  \n",
      "\n",
      "Iteration  121\n",
      "Current loss:  55936.29425121726  \n",
      "\n",
      "Iteration  122\n",
      "Current loss:  55817.09475632823  \n",
      "\n",
      "Iteration  123\n",
      "Current loss:  55699.34849347279  \n",
      "\n",
      "Iteration  124\n",
      "Current loss:  55583.025223728  \n",
      "\n",
      "Iteration  125\n",
      "Current loss:  55468.09556061735  \n",
      "\n",
      "Iteration  126\n",
      "Current loss:  55354.53094035472  \n",
      "\n",
      "Iteration  127\n",
      "Current loss:  55242.303593318866  \n",
      "\n",
      "Iteration  128\n",
      "Current loss:  55131.38651669801  \n",
      "\n",
      "Iteration  129\n",
      "Current loss:  55021.75344825252  \n",
      "\n",
      "Iteration  130\n",
      "Current loss:  54913.378841139165  \n",
      "\n",
      "Iteration  131\n",
      "Current loss:  54806.237839750735  \n",
      "\n",
      "Iteration  132\n",
      "Current loss:  54700.30625652055  \n",
      "\n",
      "Iteration  133\n",
      "Current loss:  54595.5605496504  \n",
      "\n",
      "Iteration  134\n",
      "Current loss:  54491.977801716836  \n",
      "\n",
      "Iteration  135\n",
      "Current loss:  54389.53569911752  \n",
      "\n",
      "Iteration  136\n",
      "Current loss:  54288.212512319165  \n",
      "\n",
      "Iteration  137\n",
      "Current loss:  54187.98707687006  \n",
      "\n",
      "Iteration  138\n",
      "Current loss:  54088.83877514484  \n",
      "\n",
      "Iteration  139\n",
      "Current loss:  53990.74751878654  \n",
      "\n",
      "Iteration  140\n",
      "Current loss:  53893.693731817664  \n",
      "\n",
      "Iteration  141\n",
      "Current loss:  53797.65833438873  \n",
      "\n",
      "Iteration  142\n",
      "Current loss:  53702.62272713813  \n",
      "\n",
      "Iteration  143\n",
      "Current loss:  53608.56877613554  \n",
      "\n",
      "Iteration  144\n",
      "Current loss:  53515.4787983846  \n",
      "\n",
      "Iteration  145\n",
      "Current loss:  53423.33554786053  \n",
      "\n",
      "Iteration  146\n",
      "Current loss:  53332.12220205984  \n",
      "\n",
      "Iteration  147\n",
      "Current loss:  53241.822349041264  \n",
      "\n",
      "Iteration  148\n",
      "Current loss:  53152.41997493532  \n",
      "\n",
      "Iteration  149\n",
      "Current loss:  53063.89945190553  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initialize latent features randomly:\n",
    "\n",
    "dim = 20\n",
    "util_size_rows = train_utilmatrix.shape[0]\n",
    "util_size_cols = train_utilmatrix.shape[1]\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "latent_user_feat = np.random.random((util_size_rows,dim))\n",
    "latent_movies_feat = np.random.random((dim,util_size_cols))\n",
    "\n",
    "\n",
    "#define the training parameter alpha and the regularization parameter and fit the feature matrices:\n",
    "learned_lat_users, learned_lat_movies, item_means, user_offset, loss_info = batch_GD_fsvd(util_matrix = train_utilmatrix, \n",
    "                                                                            latent_users = latent_user_feat,\n",
    "                                                                            latent_movies = latent_movies_feat,\n",
    "                                                                            alpha = 0.00001, regul = 0.00001,\n",
    "                                                                            n_iter=150, mean_normalize = False,\n",
    "                                                                            baseline = False, verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot training curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:42:29.401479Z",
     "start_time": "2020-06-29T14:42:29.273492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6)) \n",
    "ax.plot(loss_info[:,2],loss_info[:,0])\n",
    "ax.set(xlabel='Iteration', ylabel='Loss',\n",
    "       title='Loss per Iteration')\n",
    "ax.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to get predictions for test set & calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:44:38.568323Z",
     "start_time": "2020-06-29T14:44:38.553738Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preds(user_feat = None, movie_feat= None, item_means= None, offset_values= None, \n",
    "              mean_normalize = False, baseline = False, clipping = False, clip_thresholds = [0,5]):\n",
    "    \n",
    "    '''\n",
    "    returns the predictions based on learned feature vectors and additional predictors\n",
    "    \n",
    "    clipping: sets the predictions into the given range between\n",
    "    '''\n",
    "    \n",
    "    if baseline == True and mean_normalize == False:\n",
    "        prediction_matrix = np.dot(user_feat, movie_feat) + item_means + offset_values\n",
    "            \n",
    "    elif mean_normalize == True and baseline == False:\n",
    "        prediction_matrix = np.dot(user_feat, movie_feat) + item_means \n",
    "        \n",
    "    else:\n",
    "        prediction_matrix = np.dot(user_feat, movie_feat) \n",
    "        \n",
    "    if clipping == True:\n",
    "        prediction_matrix = prediction_matrix.clip(clip_thresholds[0], clip_thresholds[1])\n",
    "        \n",
    "    return prediction_matrix\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def lookup_preds(row, util_matrix = None):\n",
    "    \n",
    "    '''function looks up values in util_matrix\n",
    "        if there is no match since the movie does not have entries in the util_matrix,\n",
    "        return the mean rating of the user's existing ratings\n",
    "    '''\n",
    "    \n",
    "    #slice correct user_id\n",
    "    df_row_slice = util_matrix[util_matrix.index == row['userId']]\n",
    "    \n",
    "    #slice value of column match:\n",
    "    try:\n",
    "        df_col_val = df_row_slice.at[row['userId'],row['movie_title']]\n",
    "    except:\n",
    "        df_col_val = df_row_slice.mean(axis=1)\n",
    "    \n",
    "    return df_col_val\n",
    "\n",
    "\n",
    "\n",
    "def rmse(df):\n",
    "    diff_sqt = (df['rating'] - df['preds'])**2\n",
    "    rmse = np.sqrt(diff_sqt.sum()/len(diff_sqt))\n",
    "    print('RMSE: ', rmse)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on fitted feature matrices make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:44:46.233587Z",
     "start_time": "2020-06-29T14:44:46.163142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions:  (610, 9737)\n",
      "Shape of utility matrix:  (610, 9737)\n",
      "\n",
      " Glimpse on predictions: \n",
      "         Toy Story (1995)  Jumanji (1995)\n",
      "User_1          3.835453        4.111437\n",
      "User_2          5.000000        4.925162\n",
      "User_3          4.517374        4.450252\n",
      "User_4          4.190534        4.049313\n",
      "User_5          4.904408        4.539758\n",
      "\n",
      " Glimpse on true values: \n",
      "         Toy Story (1995)  Jumanji (1995)\n",
      "User_1               4.0             NaN\n",
      "User_2               NaN             NaN\n",
      "User_3               NaN             NaN\n",
      "User_4               NaN             NaN\n",
      "User_5               4.0             NaN\n"
     ]
    }
   ],
   "source": [
    "#get predictions (add item means if mean normalization was used for training or bias_flag was set)\n",
    "final_preds =  get_preds(learned_lat_users, learned_lat_movies, item_means, user_offset, \n",
    "                         mean_normalize = False, baseline = False, clipping=True)\n",
    "\n",
    "print('Shape of predictions: ', final_preds.shape)\n",
    "print('Shape of utility matrix: ', train_utilmatrix.shape)\n",
    "\n",
    "#add index & column labels & get glimpse on predictions:\n",
    "movie_idx = train_utilmatrix.columns\n",
    "users_idx = train_utilmatrix.index\n",
    "\n",
    "preds_matrix_df = pd.DataFrame(final_preds, index=users_idx, columns=movie_idx)\n",
    "\n",
    "print('\\n Glimpse on predictions: \\n {}'.format(preds_matrix_df.iloc[0:5,:2]))\n",
    "print('\\n Glimpse on true values: \\n {}'.format(train_utilmatrix.iloc[0:5,:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data in the test set the corresponding predictions are looked up in the fitted matrix. If no predictions are available for a given movie title in the fitted matrix, the average rating of a user is used as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:44:56.661670Z",
     "start_time": "2020-06-29T14:44:49.453527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    userId           movie_title  rating     preds\n",
      "0  User_1     Fight Club (1999)     5.0  4.621698\n",
      "1  User_1  Wolf Man, The (1941)     5.0  3.754667\n",
      "2  User_1        Dracula (1931)     4.0  5.000000 \n",
      "\n",
      "RMSE:  1.1838162882839798\n"
     ]
    }
   ],
   "source": [
    "# call function on each row to get predictions:\n",
    "test_ratings['preds'] = test_ratings.apply(lambda x: lookup_preds(x, preds_matrix_df), axis=1)\n",
    "\n",
    "print('\\n', test_ratings.head(3), '\\n')\n",
    "\n",
    "#get rmse:\n",
    "rmse_test = rmse(test_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of various other parameter combinations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:14:42.163652Z",
     "start_time": "2020-06-29T14:14:42.156066Z"
    }
   },
   "source": [
    "| n_iter | dim   |  alpha | regul | normalize | bias | clipping | TEST RMSE |\n",
    "|------|------|------|------|------|------|------|------|\n",
    "|   150  | 20| 0.00001  | 0.00001| -  | -| True  | 1.1838|\n",
    "|   100  | 20| 0.00001  | 0.00001| -  | -| True  | 1.225|\n",
    "|   150  | 20| 0.00001  | 0.00001| -  | -| -  | 1.2301|\n",
    "|   100  | 20| 0.00001  | 0.00001| -  | -| -  | 1.2936|\n",
    "|   150  | 30| 0.00001  | 0.00001| -  | -| -  | 1.5790|\n",
    "|   150  | 30| 0.00001  | 0.00001| -  | -| True  | 1.2898|\n",
    "|   150  | 20| 0.00001  | 0.00001| -  | True| -  | 2.1524|\n",
    "|   150  | 20| 0.00001  | 0.00001| -  | True| True | 1.5297|\n",
    "|   150  | 30| 0.00001  | 0.00001| -  | True| -  | 2.5173|\n",
    "|   150  | 30| 0.00001  | 0.00001| -  | True| True | 1.5320|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
